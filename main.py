# -*- coding: utf-8 -*-
"""p3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15AFqRBmPrWeUv9sPbxay3WmGKbo-GA6h
"""

import pandas
import numpy as np
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.optim as optim

"""## Question 1. Data

Download the data from the course website at https://www.cs.toronto.edu/~lczhang/321/files/p3data.zip

Unzip the file. There are three
main folders: `train`, `test_w` and `test_m`. Data in `train` will be used for
training and validation, and the data in the other folders will be used for testing.
This is so that the entire class will have the same test sets.

We've separated `test_w` and `test_m` so that we can track our model performance 
for women's shoes and men's shoes separately. Each of the test sets contain images
from 10 students who submitted images of either exclusively men's shoes or women's
shoes.

Upload this data to Google Colab.
Then, mount Google Drive from your Google Colab notebook:
"""

from google.colab import drive
drive.mount('/content/drive')

import glob

def load_data(data_path: str, images: dict):
    for file in glob.glob(data_path):
        filename = file.split("/")[-1]   # get the name of the .jpg file
        img = plt.imread(file)           # read the image as a numpy array
        images[filename] = img[:, :, :3] # remove the alpha channel


def build_numpy_arr(keys: list, data_dict: dict) -> np.ndarray:
    """Build numpy array from dictionaray
    """
    arr = np.ndarray(( int(len(keys) / 6) , 3, 2, 224, 224, 3))
    keys = keys.copy()
    i = 0

    while len(keys) > 0:
        sample_keys = keys[:6]
        keys = keys[6:]

        arr[i, 0, 0] = (data_dict[sample_keys[0]] / 255.0) - 0.5 # left shoe p1
        arr[i, 0, 1] = (data_dict[sample_keys[1]] / 255.0) - 0.5 # right shoe p1

        arr[i, 1, 0] = (data_dict[sample_keys[2]] / 255.0) - 0.5 # left shoe p2
        arr[i, 1, 1] = (data_dict[sample_keys[3]] / 255.0) - 0.5 # right shoe p2

        arr[i, 2, 0] = (data_dict[sample_keys[4]] / 255.0) - 0.5 # left shoe p3
        arr[i, 2, 1] = (data_dict[sample_keys[5]] / 255.0) - 0.5 # right shoe p3

        i += 1

    return arr

train_images = {}
load_data("/content/drive/My Drive/CSC321/data/train/*.jpg", train_images)
print("training data loaded")

test_m_images = {}
load_data("/content/drive/My Drive/CSC321/data/test_m/*.jpg", test_m_images)
print("test_m loaded")

test_w_images = {}
load_data("/content/drive/My Drive/CSC321/data/test_w/*.jpg", test_w_images)
print("test_w loaded")


keys = list(train_images.keys())
keys.sort()
train_data = build_numpy_arr(keys[120:], train_images)

valid_data = build_numpy_arr(keys[:120], train_images)

keys = list(test_m_images.keys())
keys.sort()
test_m = build_numpy_arr(keys, test_m_images)

keys = list(test_w_images.keys())
keys.sort()
test_w = build_numpy_arr(keys, test_w_images)

plt.figure()
plt.imshow(train_data[4,0,0,:,:,:]) # left shoe of first pair submitted by 5th student
plt.figure()
plt.imshow(train_data[4,0,1,:,:,:]) # right shoe of first pair submitted by 5th student
plt.figure()
plt.imshow(train_data[4,1,1,:,:,:]) # right shoe of second pair submitted by 5th student

def generate_same_pair(data: np.ndarray) -> np.ndarray:
    """Returns same pairs of shoes as an numpy array concatenated together along
    height (top: left, bottom: right)
    """
    same_pairs = np.ndarray((data.shape[0] * 3, 448, 224, 3))

    j = 0
    for i in range(0, data.shape[0]):
      left_shoe = data[i, 0, 0]
      right_shoe = data[i, 0, 1]
      same_pairs[j] = np.concatenate((left_shoe, right_shoe), axis=0)

      left_shoe = data[i, 1, 0]
      right_shoe = data[i, 1, 1]
      same_pairs[j + 1] = np.concatenate((left_shoe, right_shoe), axis=0)

      left_shoe = data[i, 2, 0]
      right_shoe = data[i, 2, 1]
      same_pairs[j + 2] = np.concatenate((left_shoe, right_shoe), axis=0)

      j += 3

    return same_pairs

print(train_data.shape) # if this is [N, 3, 2, 224, 224, 3]
print(generate_same_pair(train_data).shape) # should be [N*3, 448, 224, 3]
plt.imshow(generate_same_pair(train_data)[0]) # should show 2 shoes from the same pair


def generate_different_pair(data: np.ndarray) -> np.ndarray:
    """Returns different pairs of shoes as an numpy array concatenated together along
    height (top: left, bottom: right)
    """
    same_pairs = np.ndarray((data.shape[0] * 3, 448, 224, 3))

    j = 0
    for i in range(0, data.shape[0]):
      left_shoe = data[i, 0, 0]
      right_shoe = data[i, 1, 1]
      same_pairs[j] = np.concatenate((left_shoe, right_shoe), axis=0)

      left_shoe = data[i, 1, 0]
      right_shoe = data[i, 2, 1]
      same_pairs[j + 1] = np.concatenate((left_shoe, right_shoe), axis=0)

      left_shoe = data[i, 2, 0]
      right_shoe = data[i, 0, 1]
      same_pairs[j + 2] = np.concatenate((left_shoe, right_shoe), axis=0)

      j += 3

    return same_pairs

print(train_data.shape) # if this is [N, 3, 2, 224, 224, 3]
print(generate_different_pair(train_data).shape) # should be [N*3, 448, 224, 3]
plt.imshow(generate_different_pair(train_data)[0]) # should show 2 shoes from different pairs


"""

A CNN model in PyTorch called `CNN` that will take images of size
$3 \times 448 \times 224$, and classify whether the images contain shoes from
the same pair or from different pairs.

The model contains the following layers:

- A convolution layer that takes in 3 channels, and outputs $n$ channels.
- A $2 \times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)
- A second convolution layer that takes in $n$ channels, and outputs $n \times 2$ channels.
- A $2 \times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)
- A third convolution layer that takes in $n \times 2$ channels, and outputs $n \times 4$ channels.
- A $2 \times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)
- A fourth convolution layer that takes in $n \times 4$ channels, and outputs $n \times 8$ channels.
- A $2 \times 2$ downsampling (either using a strided convolution in the previous step, or max pooling)
- A fully-connected layer with 100 hidden units
- A fully-connected layer with 2 hidden units
"""

class CNN(nn.Module):
    def __init__(self, n=4):
        super(CNN, self).__init__()

        self.n = n
        self.maxPool = nn.MaxPool2d(2, 2)
        # 3 x 448 x 224
        self.conv1 = nn.Conv2d(in_channels=3, 
                               out_channels=n, 
                               kernel_size=3, 
                               padding=1)
        # n x 224 x 112
        self.conv2 = nn.Conv2d(in_channels=n, 
                               out_channels=2*n,
                               kernel_size=3,
                               padding=1)
        # 2n x 112 x 56
        self.conv3 = nn.Conv2d(in_channels=2*n, 
                               out_channels=4*n,
                               kernel_size=3,
                               padding=1)
        # 4n x 56 x 28
        self.conv4 = nn.Conv2d(in_channels=4*n, 
                               out_channels=8*n,
                               kernel_size=3,
                               padding=1)
        # 8n x 28 x 14
        self.fc1 = nn.Linear((8 * n) * 28 * 14, 100)
        self.fc2 = nn.Linear(100, 2)
    
    def forward(self, X):
        # convolution layers
        X = self.maxPool(torch.relu(self.conv1(X)))
        X = self.maxPool(torch.relu(self.conv2(X)))
        X = self.maxPool(torch.relu(self.conv3(X)))
        X = self.maxPool(torch.relu(self.conv4(X)))

        X = X.view(-1, 8 * self.n * 28 * 14)
        # fully connected layers
        X = torch.relu(self.fc1(X))
        return self.fc2(X)

# model = CNN()
# sample = generate_different_pair(train_data)[0].T
# sample = torch.from_numpy(sample).unsqueeze(0)
# print(model.forward(sample.float()))

"""
A CNN model in PyTorch called `CNNChannel` that contains the same layers as
previous model, but with one crucial difference: instead of starting with an image
of shape $3 \times 448 \times 224$, we will first manipulate the image so that the
left and right shoes images are concatenated along the **channel** dimension.

<img src="https://www.cs.toronto.edu/~lczhang/321/hw/p3model.png" width="400px" />
"""

class CNNChannel(nn.Module):
    def __init__(self, n=4):
        super(CNNChannel, self).__init__()
        
        self.n = n
        self.maxPool = nn.MaxPool2d(2, 2)
        # 6 x 224 x 224
        self.conv1 = nn.Conv2d(in_channels=6, 
                               out_channels=n, 
                               kernel_size=3, 
                               padding=1)
        # n x 112 x 112
        self.conv2 = nn.Conv2d(in_channels=n, 
                               out_channels=2*n,
                               kernel_size=3,
                               padding=1)
        # 2n x 56 x 56
        self.conv3 = nn.Conv2d(in_channels=2*n, 
                               out_channels=4*n,
                               kernel_size=3,
                               padding=1)
        # 4n x 28 x 28
        self.conv4 = nn.Conv2d(in_channels=4*n, 
                               out_channels=8*n,
                               kernel_size=3,
                               padding=1)
        # 8n x 14 x 14
        self.fc1 = nn.Linear((8 * n) * 14 * 14, 100)
        self.fc2 = nn.Linear(100, 2)

    def forward(self, X):
        left_shoe = X[:, :, :224, :]
        right_shoe = X[:, :, 224:, :]

        X = torch.cat((left_shoe, right_shoe), dim=1)

        # convolution layers
        X = self.maxPool(torch.relu(self.conv1(X)))
        X = self.maxPool(torch.relu(self.conv2(X)))
        X = self.maxPool(torch.relu(self.conv3(X)))
        X = self.maxPool(torch.relu(self.conv4(X)))

        X = X.view(-1, 8 * self.n * 14 * 14)
        # fully connected layers
        X = torch.relu(self.fc1(X))
        return self.fc2(X)

# model = CNNChannel()
# sample = generate_different_pair(train_data)[0].T
# sample = torch.from_numpy(sample).unsqueeze(0)
# print(model.forward(sample.float()))


def get_prediction(model, input_img) -> str:
    """
    """
    pair = torch.from_numpy(input_img.transpose((2, 0, 1))).unsqueeze(0)

    y = model_cnn_channel(pair.float())
    y = torch.relu(y).max(1, keepdim=True)[1]

    return "Pair is: " + ("same" if y == 1 else "different")


def get_accuracy(model, data, batch_size=50):
    """Compute the model accuracy on the data set. This function returns two
    separate values: the model accuracy on the positive samples,
    and the model accuracy on the negative samples.

    Example Usage:

    >>> model = CNN() # create untrained model
    >>> pos_acc, neg_acc= get_accuracy(model, valid_data)
    >>> false_positive = 1 - pos_acc
    >>> false_negative = 1 - neg_acc
    """
    model.eval()
    n = data.shape[0]

    data_pos = generate_same_pair(data)      # should have shape [n * 3, 448, 224, 3]
    data_neg = generate_different_pair(data) # should have shape [n * 3, 448, 224, 3]

    # import pdb; pdb.set_trace()

    pos_correct = 0
    for i in range(0, len(data_pos), batch_size):
        xs = torch.Tensor(data_pos[i:i+batch_size].transpose((0, 3, 1, 2)))
        zs = model(xs)
        zs = torch.relu(zs)
        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit
        pred = pred.detach().numpy()
        pos_correct += (pred == 1).sum()
    
    neg_correct = 0
    for i in range(0, len(data_neg), batch_size):
        xs = torch.Tensor(data_neg[i:i+batch_size].transpose((0, 3, 1, 2)))
        zs = model(xs)
        pred = zs.max(1, keepdim=True)[1] # get the index of the max logit
        pred = pred.detach().numpy()
        neg_correct += (pred == 0).sum()

    return pos_correct / (n * 3), neg_correct / (n * 3)


def plot_learning_curve(iters, losses, iters_sub, train_accs, val_accs):
    """
    Plot the learning curve.
    """
    plt.title("Learning Curve: Loss per Iteration")
    plt.plot(iters, losses, label="Train")
    plt.xlabel("Iterations")
    plt.ylabel("Loss")
    plt.show()

    plt.title("Learning Curve: Accuracy per Iteration")
    plt.plot(iters_sub, train_accs, label="Train")
    plt.plot(iters_sub, val_accs, label="Validation")
    plt.xlabel("Iterations")
    plt.ylabel("Accuracy")
    plt.legend(loc='best')
    plt.show()

def train_model(model,
                training_data=train_data,
                validation_data=valid_data,
                batch_size=8,
                learning_rate=0.001,
                weight_decay=0,
                max_iters=1000,
                checkpoint_path=None):
    """Train CNN or CNNChannel Model on shoes dataset.
    Checkpoint path must be something like
    checkpoint_path = '/content/drive/My Drive/CSC321/mlp/ckpt-{}.pk'
    """
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(),
                           lr=learning_rate,
                           weight_decay=weight_decay)
    # import pdb; pdb.set_trace()
    
    iters, losses = [], []
    iters_sub, train_accs, val_accs  = [], [] ,[]

    data_pos = generate_same_pair(training_data)
    data_neg = generate_different_pair(training_data)

    # ts = torch.reshape(ts, (ts.shape[0], 1))

    n = 0
    while True:
        np.random.shuffle(data_pos)
        np.random.shuffle(data_neg)
        for i in range(0, data_pos.shape[0], batch_size):
            if (i + batch_size) > data_pos.shape[0]:
                break

            pos_samples = data_pos[i:i + (batch_size//2)]
            pos_samples = torch.from_numpy(pos_samples.transpose((0, 3, 1, 2)))

            neg_samples = data_neg[i:i + (batch_size//2)]
            neg_samples = torch.from_numpy(neg_samples.transpose((0, 3, 1, 2)))

            xs = torch.cat((pos_samples, neg_samples))

            ts = np.concatenate((np.ones(batch_size // 2), 
                         np.zeros(batch_size // 2)))
            ts = torch.Tensor(ts).long()

            indices = torch.randperm(ts.shape[0]) # shuffle indices

            ts = ts[indices]
            xs = xs[indices]

            zs = model(xs.float())
            loss = criterion(zs, ts)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()

            iters.append(n)
            losses.append(float(loss)/batch_size)  # compute *average* loss

            if n % 50 == 0:
                iters_sub.append(n)
                train_cost = float(loss.detach().numpy())

                train_pos_acc, train_neg_acc = get_accuracy(model, training_data, batch_size)
                train_accs.append((train_pos_acc + train_neg_acc) / 2.0)

                val_pos_acc, val_neg_acc = get_accuracy(model, validation_data, batch_size)
                val_accs.append((val_pos_acc + val_neg_acc) / 2.0)
                print("Iter %d. [Val Acc %.0f%%] [Train Acc %.0f%%, Loss %f]" % (
                      n, ((val_pos_acc + val_neg_acc) / 2.0) * 100, 
                      ((train_pos_acc + train_neg_acc) / 2.0) * 100, 
                      train_cost))

                if (checkpoint_path is not None) and n > 0:
                    torch.save(model.state_dict(), checkpoint_path.format(n))

            # increment the iteration number
            n += 1

            if n > max_iters:
                return iters, losses, iters_sub, train_accs, val_accs



# Batch size of 32 worked well. Any lower cause very noisy steps for gradient.
# Learining rate of 0.001 seemed to work well after a few trial runs with diff
# rates.

model_cnn = CNN(2)
cnn_curve = train_model(model_cnn, training_data=train_data, max_iters=1300,
                        batch_size=32, learning_rate=0.001,
                        checkpoint_path="/content/drive/My Drive/CSC321/p3-chkpts/CNN/ckpt-{}.pk")

plot_learning_curve(*(cnn_curve))

model_cnn_channel = CNNChannel()
cnn_channel_curve = train_model(model_cnn_channel, training_data=train_data,
                                max_iters=750, batch_size=32, learning_rate=0.001,
                                checkpoint_path="/content/drive/My Drive/CSC321/p3-chkpts/CNNChannel/ckpt-{}.pk")

plot_learning_curve(*(cnn_channel_curve))


print("CNN Model")
plot_learning_curve(*(cnn_curve))

print("CNNChannel Model")
plot_learning_curve(*(cnn_channel_curve))





# model_cnn.load_state_dict(torch.load('/content/drive/My Drive/CSC321/p3-chkpts/CNN/ckpt-1000.pk'))
# model_cnn_channel.load_state_dict(torch.load('/content/drive/My Drive/CSC321/p3-chkpts/CNNChannel/ckpt-400.pk'))

acc = get_accuracy(model_cnn, test_m)
print("Accuracy for CNN model on male shoes: (+) {}% , (-) {}%".format(acc[0] * 100.0, acc[1] * 100.0))

acc = get_accuracy(model_cnn, test_w)
print("Accuracy for CNN model on female shoes: (+) {}% , (-) {}%".format(acc[0] * 100.0, acc[1] * 100.0))

print()

acc = get_accuracy(model_cnn_channel, test_m)
print("Accuracy for CNNChannel model on male shoes: (+) {}% , (-) {}%".format(acc[0] * 100.0, acc[1] * 100.0))

acc = get_accuracy(model_cnn_channel, test_w)
print("Accuracy for CNNChannel model on female shoes: (+) {}% , (-) {}%".format(acc[0] * 100.0, acc[1] * 100.0))




pairs = generate_same_pair(test_m)

# Correctly Classified Pair (Male)
plt.figure()
plt.imshow(pairs[0]) # display the image
print("(1) " + get_prediction(model_cnn_channel, pairs[0]) )

# Incorrectly Classified Pair (Male)
plt.figure()
plt.imshow(pairs[21]) # display the image
print("(2) " + get_prediction(model_cnn_channel, pairs[21]) )

pairs = generate_same_pair(test_w)

# Correctly Classified Pair (Female)
plt.figure()
plt.imshow(pairs[0]) # display the image
print("(1) " + get_prediction(model_cnn_channel, pairs[0]) )

# Incorrectly Classified Pair (Female)
plt.figure()
plt.imshow(pairs[9]) # display the image
print("(2) " + get_prediction(model_cnn_channel, pairs[9]) )
